"""
è‚¡ç¥¨æ•°æ®è·å–æ¨¡å— - ä½¿ç”¨baostockè·å–Aè‚¡æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰
"""
import baostock as bs
import pandas as pd
from datetime import datetime, timedelta
from typing import Optional
from .cache import StockDataCache
from . import baostock_global


class BaoStockDataFetcher:
    """Aè‚¡æ•°æ®è·å–å™¨ - ä½¿ç”¨baostockï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    
    def __init__(self, enable_cache: bool = True, cache_path: str = "data/stock_cache.db"):
        """
        åˆå§‹åŒ–æ•°æ®è·å–å™¨
        
        Args:
            enable_cache: æ˜¯å¦å¯ç”¨ç¼“å­˜
            cache_path: ç¼“å­˜æ•°æ®åº“è·¯å¾„
        """
        self.enable_cache = enable_cache
        self.cache = StockDataCache(cache_path) if enable_cache else None
        self.lg = None
        self._login()
    
    def _login(self):
        """ç™»å½•baostockï¼ˆä½¿ç”¨å…¨å±€ç™»å½•ï¼‰"""
        try:
            self.lg = baostock_global.global_login()
        except Exception as e:
            print(f"ç™»å½•baostockå¤±è´¥: {e}")
            raise
    
    def _logout(self):
        """ç™»å‡ºbaostockï¼ˆä½¿ç”¨å…¨å±€ç™»å‡ºï¼‰"""
        if self.lg:
            try:
                baostock_global.global_logout()
            except Exception:
                pass
            self.lg = None
    
    def __del__(self):
        """ææ„æ—¶è‡ªåŠ¨ç™»å‡ºï¼ˆå·²ç¦ç”¨ï¼Œé¿å…å½±å“å…¶ä»–å®ä¾‹ï¼‰"""
        pass
    
    def close(self):
        """æ‰‹åŠ¨å…³é—­è¿æ¥"""
        self._logout()
    
    def get_stock_list(self) -> pd.DataFrame:
        """
        è·å–Aè‚¡æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨ï¼ˆå¸¦ç¼“å­˜ï¼‰
        
        Returns:
            DataFrameåŒ…å«: code, nameç­‰ä¿¡æ¯
        """
        try:
            # å°è¯•ä»ç¼“å­˜è·å–
            if self.enable_cache and self.cache:
                cached_data = self.cache.get_stock_list(max_age_hours=24)
                if cached_data is not None:
                    print(f"ä»ç¼“å­˜è·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œå…± {len(cached_data)} åªè‚¡ç¥¨")
                    return cached_data
            
            # å°è¯•è·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œä½¿ç”¨å¤šä¸ªæ—¥æœŸç­–ç•¥
            dates_to_try = []
            
            # ç­–ç•¥1: ä½¿ç”¨å·²çŸ¥çš„å†å²äº¤æ˜“æ—¥ï¼ˆbaostockæ•°æ®é€šå¸¸æœ‰å»¶è¿Ÿï¼‰
            # ä½¿ç”¨2024å¹´åº•å’Œ2025å¹´åˆçš„æ—¥æœŸ
            known_trading_dates = [
                '2025-01-30', '2025-01-29', '2025-01-28', '2025-01-27', '2025-01-24', '2025-01-23', '2025-01-22', '2025-01-21',
                '2025-01-20', '2025-01-17', '2025-01-16', '2025-01-15', '2025-01-14',
                '2025-01-13', '2025-01-10', '2025-01-09', '2025-01-08', '2025-01-07',
                '2025-01-06', '2025-01-03', '2025-01-02', '2024-12-31', '2024-12-30',
                '2024-12-27', '2024-12-26', '2024-12-25', '2024-12-24', '2024-12-23'
            ]
            dates_to_try.extend(known_trading_dates)
            
            # ç­–ç•¥2: ä»ä»Šå¤©å¼€å§‹å¾€å‰æ‰¾æœ€è¿‘çš„60å¤©ï¼ˆä½œä¸ºåå¤‡ï¼‰
            for i in range(60):
                date = (datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d')
                if date not in dates_to_try:
                    dates_to_try.append(date)
            
            for date in dates_to_try:
                rs = bs.query_all_stock(day=date)
                
                if rs.error_code != '0':
                    continue
                
                data_list = []
                while (rs.error_code == '0') & rs.next():
                    data_list.append(rs.get_row_data())
                
                result = pd.DataFrame(data_list, columns=rs.fields)
                
                # è¿‡æ»¤å‡ºAè‚¡è‚¡ç¥¨ï¼ˆæ’é™¤æŒ‡æ•°ï¼‰
                # ä¸Šæµ·ä¸»æ¿: sh.600000-604999
                # ä¸Šæµ·ç§‘åˆ›æ¿: sh.688000-688999
                # æ·±åœ³ä¸»æ¿: sz.000xxx, sz.001xxx
                # æ·±åœ³åˆ›ä¸šæ¿: sz.300xxx
                a_stocks = result[
                    (result['code'].str.startswith('sh.60')) |  # ä¸Šæµ·ä¸»æ¿
                    (result['code'].str.startswith('sh.688')) |  # ä¸Šæµ·ç§‘åˆ›æ¿
                    (result['code'].str.startswith('sz.000')) |  # æ·±åœ³ä¸»æ¿
                    (result['code'].str.startswith('sz.001')) |  # æ·±åœ³ä¸»æ¿
                    (result['code'].str.startswith('sz.300'))    # æ·±åœ³åˆ›ä¸šæ¿
                ].copy()
                
                # å¦‚æœæ²¡æœ‰Aè‚¡è‚¡ç¥¨ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªæ—¥æœŸ
                if len(a_stocks) == 0:
                    continue
                
                # è¿‡æ»¤å‡ºæ­£å¸¸äº¤æ˜“çš„è‚¡ç¥¨ï¼ˆstatus=1ï¼‰
                # status=1: æ­£å¸¸äº¤æ˜“, status=0: åœç‰Œ, å…¶ä»–çŠ¶æ€å¯èƒ½è¡¨ç¤ºé€€å¸‚ç­‰
                # æ³¨æ„ï¼šæŸäº›æƒ…å†µä¸‹APIå¯èƒ½ä¸è¿”å›tradeStatuså­—æ®µï¼Œéœ€è¦æ£€æŸ¥
                if 'tradeStatus' in a_stocks.columns:
                    a_stocks = a_stocks[a_stocks['tradeStatus'] == '1'].copy()
                else:
                    # å¦‚æœæ²¡æœ‰tradeStatuså­—æ®µï¼Œè®°å½•è­¦å‘Šå¹¶ç»§ç»­ä½¿ç”¨æ‰€æœ‰Aè‚¡è‚¡ç¥¨
                    print(f"è­¦å‘Š: APIæœªè¿”å›tradeStatuså­—æ®µï¼Œå°†ä½¿ç”¨æ‰€æœ‰Aè‚¡è‚¡ç¥¨ï¼ˆå…±{len(a_stocks)}åªï¼‰")
                
                # æ ‡å‡†åŒ–åˆ—å
                rename_dict = {
                    'code': 'code',
                    'code_name': 'name',
                    'tradeStatus': 'status'
                }
                # åªé‡å‘½åå®é™…å­˜åœ¨çš„åˆ—
                rename_dict = {k: v for k, v in rename_dict.items() if k in a_stocks.columns}
                a_stocks = a_stocks.rename(columns=rename_dict)
                
                # æ·»åŠ å¸‚åœºæ ‡è¯†
                a_stocks['market'] = a_stocks['code'].apply(
                    lambda x: 'SH' if x.startswith('sh.') else 'SZ'
                )
                
                # å»é™¤ä»£ç å‰ç¼€ï¼ˆsh./sz.ï¼‰
                a_stocks['code'] = a_stocks['code'].str.replace(r'^(sh|sz)\.', '', regex=True)
                
                print(f"æˆåŠŸè·å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆæ—¥æœŸ: {date}ï¼‰ï¼Œå…± {len(a_stocks)} åªè‚¡ç¥¨")
                
                # ä¿å­˜åˆ°ç¼“å­˜
                if self.enable_cache and self.cache:
                    self.cache.save_stock_list(a_stocks)
                    print("å·²ä¿å­˜åˆ°ç¼“å­˜")
                
                return a_stocks[['code', 'name', 'status', 'market']]
            
            print("è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: æ— æ³•æ‰¾åˆ°å¯ç”¨çš„äº¤æ˜“æ—¥")
            return pd.DataFrame()
            
        except Exception as e:
            print(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return pd.DataFrame()
    
    def get_stock_spot(self, code: str) -> dict:
        """
        è·å–å•åªè‚¡ç¥¨çš„å®æ—¶è¡Œæƒ…ï¼ˆå¸¦ç¼“å­˜ï¼‰
        
        Args:
            code: è‚¡ç¥¨ä»£ç  (å¦‚: 000001, 600000)
            
        Returns:
            åŒ…å«å®æ—¶è¡Œæƒ…æ•°æ®çš„å­—å…¸ï¼ˆä¸­æ–‡é”®åï¼‰
        """
        try:
            # å°è¯•ä»ç¼“å­˜è·å–
            if self.enable_cache and self.cache:
                cached_data = self.cache.get_spot_data(code, max_age_hours=1)
                if cached_data is not None:
                    # æ£€æŸ¥ç¼“å­˜æ•°æ®æ ¼å¼æ˜¯å¦æ˜¯ä¸­æ–‡é”®å
                    if 'æœ€æ–°ä»·' in cached_data:
                        print(f"ä»ç¼“å­˜è·å–è‚¡ç¥¨ {code} å®æ—¶è¡Œæƒ…")
                        return cached_data
                    else:
                        # ç¼“å­˜æ˜¯æ—§æ ¼å¼ï¼Œé‡æ–°è·å–
                        print(f"ç¼“å­˜æ ¼å¼æ—§ï¼Œé‡æ–°è·å–è‚¡ç¥¨ {code} å®æ—¶è¡Œæƒ…")
            
            # æ ‡å‡†åŒ–ä»£ç æ ¼å¼
            if '.' not in code:
                if code.startswith('6'):
                    code = f'sh.{code}'
                else:
                    code = f'sz.{code}'
            
            # è·å–æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®ä½œä¸º"å®æ—¶"è¡Œæƒ…
            # ä»ä»Šå¤©å¼€å§‹å¾€å‰æŸ¥æ‰¾æœ€è¿‘çš„äº¤æ˜“æ—¥
            for i in range(30):
                date = (datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d')
                rs = bs.query_history_k_data_plus(
                    code,
                    "date,code,open,high,low,close,volume,amount,pctChg,turn",
                    start_date=date,
                    end_date=date,
                    frequency="d",
                    adjustflag="3"
                )
                
                if rs.error_code != '0':
                    continue
                
                data_list = []
                while (rs.error_code == '0') & rs.next():
                    data_list.append(rs.get_row_data())
                
                if data_list:
                    result = pd.DataFrame(data_list, columns=rs.fields)
                    raw_data = result.iloc[0].to_dict()
                    
                    # è½¬æ¢ä¸ºä¸­æ–‡é”®å
                    spot_data = {
                        'æ—¥æœŸ': raw_data.get('date', ''),
                        'è‚¡ç¥¨ä»£ç ': raw_data.get('code', ''),
                        'å¼€ç›˜ä»·': self._safe_float(raw_data.get('open')),
                        'æœ€é«˜ä»·': self._safe_float(raw_data.get('high')),
                        'æœ€ä½ä»·': self._safe_float(raw_data.get('low')),
                        'æœ€æ–°ä»·': self._safe_float(raw_data.get('close')),
                        'æˆäº¤é‡': self._safe_float(raw_data.get('volume')),
                        'æˆäº¤é¢': self._safe_float(raw_data.get('amount')),
                        'æ¶¨è·Œå¹…': self._safe_float(raw_data.get('pctChg')),
                        'æ¢æ‰‹ç‡': self._safe_float(raw_data.get('turn'))
                    }
                    
                    # ä¿å­˜åˆ°ç¼“å­˜
                    if self.enable_cache and self.cache:
                        self.cache.save_spot_data(code, spot_data)
                        print(f"å·²ä¿å­˜è‚¡ç¥¨ {code} å®æ—¶è¡Œæƒ…åˆ°ç¼“å­˜")
                    
                    return spot_data
            
            return {}
            
        except Exception as e:
            print(f"è·å–è‚¡ç¥¨ {code} å®æ—¶è¡Œæƒ…å¤±è´¥: {e}")
            return {}
    
    def _safe_float(self, value, default=0.0):
        """å®‰å…¨è½¬æ¢ä¸ºæµ®ç‚¹æ•°"""
        if value is None or value == '' or value == '-':
            return default
        try:
            return float(value)
        except (ValueError, TypeError):
            return default
    
    def get_batch_spot_data(self, codes: list) -> dict:
        """
        æ‰¹é‡è·å–å¤šåªè‚¡ç¥¨çš„å®æ—¶è¡Œæƒ…ï¼ˆä¼˜åŒ–ç‰ˆï¼Œæ”¯æŒå¤§è§„æ¨¡æ•°æ®ï¼‰
        
        ä¼˜åŒ–ç‚¹ï¼š
        1. å…ˆæ‰¹é‡æ£€æŸ¥ç¼“å­˜ï¼Œå‡å°‘APIè°ƒç”¨
        2. åªæŸ¥æ‰¾ä¸€æ¬¡æœ€è¿‘äº¤æ˜“æ—¥
        3. æ‰¹é‡è·å–æ—¶æ·»åŠ é€‚å½“çš„é”™è¯¯å¤„ç†å’Œå»¶è¿Ÿ
        4. å®æ—¶ä¿å­˜åˆ°ç¼“å­˜
        5. è¿æ¥è¢«å…³é—­æ—¶è‡ªåŠ¨é‡è¿å’Œå†·å´
        
        Args:
            codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨ (å¦‚: ['000001', '600000'])
            
        Returns:
            å­—å…¸ï¼Œkeyä¸ºè‚¡ç¥¨ä»£ç ï¼Œvalueä¸ºè¡Œæƒ…æ•°æ®
        """
        import time
        try:
            result = {}
            
            if not codes:
                return result
            
            # æ­¥éª¤1: æ‰¹é‡è·å–ç¼“å­˜ä¸­æœ‰æ•ˆçš„æ•°æ®
            cache_hits = 0
            if self.enable_cache and self.cache:
                for code in codes:
                    cached_data = self.cache.get_spot_data(code, max_age_hours=1)
                    if cached_data is not None:
                        result[code] = cached_data
                        cache_hits += 1
            
            # æ­¥éª¤2: æ‰¾å‡ºéœ€è¦ä»APIè·å–çš„è‚¡ç¥¨
            codes_need_fetch = [code for code in codes if code not in result]
            
            if not codes_need_fetch:
                print(f"æ‰€æœ‰ {len(codes)} åªè‚¡ç¥¨çš„å®æ—¶è¡Œæƒ…éƒ½æ¥è‡ªç¼“å­˜ï¼ˆå‘½ä¸­ {cache_hits} åªï¼‰")
                return result
            
            print(f"éœ€è¦ä»APIè·å– {len(codes_need_fetch)} åªè‚¡ç¥¨çš„å®æ—¶è¡Œæƒ…ï¼ˆç¼“å­˜å‘½ä¸­ {cache_hits} åªï¼‰")
            
            # æ­¥éª¤3: ä¼˜åŒ–æ—¥æœŸæŸ¥æ‰¾ç­–ç•¥ - åªæŸ¥æ‰¾ä¸€æ¬¡æœ€è¿‘äº¤æ˜“æ—¥
            trading_date = None
            # ä½¿ç”¨ä¸Šæµ·ä¸»æ¿çš„ä¸€åªå¤§ç›˜è‚¡ä½œä¸ºæµ‹è¯•ï¼ˆ600519èŒ…å°é€šå¸¸æ¯å¤©éƒ½æœ‰æ•°æ®ï¼‰
            test_codes = ['sh.600519', 'sh.600036', 'sz.000001', 'sh.600000']
            
            for test_code in test_codes:
                for i in range(10):  # å‡å°‘æœç´¢èŒƒå›´åˆ°10å¤©
                    date = (datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d')
                    
                    try:
                        rs = bs.query_history_k_data_plus(
                            test_code,
                            "date",
                            start_date=date,
                            end_date=date,
                            frequency="d",
                            adjustflag="3"
                        )
                        
                        if rs.error_code == '0':
                            data_list = []
                            while (rs.error_code == '0') & rs.next():
                                data_list.append(rs.get_row_data())
                            if data_list:
                                trading_date = date
                                print(f"æ‰¾åˆ°æœ€è¿‘äº¤æ˜“æ—¥: {trading_date} (ä½¿ç”¨æµ‹è¯•ç  {test_code})")
                                break
                    except Exception as e:
                        print(f"æŸ¥æ‰¾äº¤æ˜“æ—¥æ—¶å‡ºé”™: {e}")
                        continue
                if trading_date:
                    break
            
            if not trading_date:
                # å¦‚æœæ‰¾ä¸åˆ°ï¼Œä½¿ç”¨æ˜¨å¤©æˆ–ä»Šå¤©çš„æ—¥æœŸ
                trading_date = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
                print(f"æœªæ‰¾åˆ°æœ‰æ•ˆäº¤æ˜“æ—¥ï¼Œä½¿ç”¨é»˜è®¤æ—¥æœŸ: {trading_date}")
            
            # æ­¥éª¤4: æ‰¹é‡è·å–æ‰€æœ‰è‚¡ç¥¨æ•°æ®ï¼Œæ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
            success_count = 0
            total_count = len(codes_need_fetch)
            batch_start_time = time.time()
            
            # è¿æ¥é”™è¯¯è®¡æ•°å™¨
            connection_errors = 0
            max_connection_errors = 5
            
            for idx, code in enumerate(codes_need_fetch):
                if code in result:
                    continue
                
                # æ ‡å‡†åŒ–ä»£ç æ ¼å¼
                code_with_prefix = code
                if '.' not in code:
                    if code.startswith('6'):
                        code_with_prefix = f'sh.{code}'
                    else:
                        code_with_prefix = f'sz.{code}'
                
                try:
                    rs = bs.query_history_k_data_plus(
                        code_with_prefix,
                        "date,code,open,high,low,close,volume,amount,pctChg,turn",
                        start_date=trading_date,
                        end_date=trading_date,
                        frequency="d",
                        adjustflag="3"
                    )
                    
                    if rs.error_code != '0':
                        # æ£€æŸ¥æ˜¯å¦æ˜¯è¿æ¥é”™è¯¯
                        if 'è¿æ¥' in rs.error_msg or 'ç½‘ç»œ' in rs.error_msg:
                            connection_errors += 1
                            print(f"âš ï¸ è¿æ¥é”™è¯¯ {connection_errors}/{max_connection_errors}: {rs.error_msg}")
                            
                            # å¦‚æœè¿æ¥é”™è¯¯å¤ªå¤šï¼Œå¢åŠ å†·å´æ—¶é—´
                            if connection_errors >= max_connection_errors:
                                print(f"â¸ï¸ è¿æ¥é”™è¯¯è¿‡å¤šï¼Œå†·å´5ç§’åé‡è¯•...")
                                time.sleep(5)
                                connection_errors = 0
                            else:
                                time.sleep(1)  # çŸ­æš‚å†·å´
                            continue
                        
                        # APIé”™è¯¯ï¼Œè®°å½•ä½†ç»§ç»­
                        if idx % 50 == 0:  # æ¯50åªè®°å½•ä¸€æ¬¡ï¼Œé¿å…æ—¥å¿—è¿‡å¤š
                            print(f"APIé”™è¯¯ {code}: {rs.error_msg}")
                        continue
                    
                    data_list = []
                    while (rs.error_code == '0') & rs.next():
                        data_list.append(rs.get_row_data())
                    
                    if data_list:
                        df = pd.DataFrame(data_list, columns=rs.fields)
                        raw_data = df.iloc[0].to_dict()
                        
                        # è½¬æ¢ä¸ºä¸­æ–‡é”®åï¼ˆä¸get_stock_spotä¿æŒä¸€è‡´ï¼‰
                        spot_data = {
                            'æ—¥æœŸ': raw_data.get('date', ''),
                            'è‚¡ç¥¨ä»£ç ': raw_data.get('code', ''),
                            'å¼€ç›˜ä»·': self._safe_float(raw_data.get('open')),
                            'æœ€é«˜ä»·': self._safe_float(raw_data.get('high')),
                            'æœ€ä½ä»·': self._safe_float(raw_data.get('low')),
                            'æœ€æ–°ä»·': self._safe_float(raw_data.get('close')),
                            'æˆäº¤é‡': self._safe_float(raw_data.get('volume')),
                            'æˆäº¤é¢': self._safe_float(raw_data.get('amount')),
                            'æ¶¨è·Œå¹…': self._safe_float(raw_data.get('pctChg')),
                            'æ¢æ‰‹ç‡': self._safe_float(raw_data.get('turn'))
                        }
                        result[code] = spot_data
                        success_count += 1
                        connection_errors = 0  # æˆåŠŸæ—¶é‡ç½®é”™è¯¯è®¡æ•°
                        
                        # å®æ—¶ä¿å­˜åˆ°ç¼“å­˜
                        if self.enable_cache and self.cache:
                            self.cache.save_spot_data(code, spot_data)
                    else:
                        # è¯¥è‚¡ç¥¨åœ¨è¿™ä¸ªæ—¥æœŸæ²¡æœ‰æ•°æ®ï¼Œå¯èƒ½æ˜¯åœç‰Œ
                        pass
                    
                except Exception as e:
                    error_msg = str(e)
                    # æ£€æŸ¥æ˜¯å¦æ˜¯è¿æ¥è¢«å…³é—­çš„é”™è¯¯
                    if '10054' in error_msg or 'è¿œç¨‹ä¸»æœº' in error_msg or 'Connection' in error_msg:
                        connection_errors += 1
                        print(f"âš ï¸ è¿æ¥è¢«æœåŠ¡å™¨å…³é—­ {connection_errors}/{max_connection_errors}: {code}")
                        
                        if connection_errors >= max_connection_errors:
                            print(f"â¸ï¸ æœåŠ¡å™¨é™åˆ¶è¿æ¥ï¼Œå†·å´10ç§’...")
                            time.sleep(10)
                            connection_errors = 0
                        else:
                            time.sleep(2)  # çŸ­æš‚å†·å´
                        continue
                    
                    # å•ä¸ªè‚¡ç¥¨å‡ºé”™ä¸å½±å“å…¶ä»–è‚¡ç¥¨
                    if idx % 50 == 0:
                        print(f"è·å– {code} å‡ºé”™: {e}")
                    continue
                
                # æ¯100åªè‚¡ç¥¨æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦å’Œé¢„ä¼°æ—¶é—´
                if (idx + 1) % 100 == 0:
                    elapsed = time.time() - batch_start_time
                    rate = (idx + 1) / elapsed if elapsed > 0 else 0
                    remaining = (total_count - idx - 1) / rate if rate > 0 else 0
                    print(f"è¿›åº¦: {idx + 1}/{total_count} ({(idx + 1) / total_count * 100:.1f}%), "
                          f"é€Ÿåº¦: {rate:.1f}åª/ç§’, é¢„ä¼°å‰©ä½™: {remaining:.0f}ç§’")
                
                # å¢åŠ è¯·æ±‚é—´éš” - æ¯åªè‚¡ç¥¨ä¹‹é—´æ·»åŠ å»¶è¿Ÿ
                # æ ¹æ®è¿æ¥é”™è¯¯æƒ…å†µåŠ¨æ€è°ƒæ•´å»¶è¿Ÿ
                base_delay = 0.05  # åŸºç¡€å»¶è¿Ÿ50æ¯«ç§’
                if connection_errors > 0:
                    base_delay = 0.2  # æœ‰é”™è¯¯æ—¶å¢åŠ å»¶è¿Ÿåˆ°200æ¯«ç§’
                
                if (idx + 1) % 5 == 0:  # æ¯5åªè‚¡ç¥¨å»¶è¿Ÿä¸€æ¬¡
                    time.sleep(base_delay)
            
            elapsed_total = time.time() - batch_start_time
            success_rate = success_count / total_count * 100 if total_count > 0 else 0
            avg_speed = total_count / elapsed_total if elapsed_total > 0 else 0
            
            print(f"æ‰¹é‡è·å–å®Œæˆï¼ŒæˆåŠŸ {success_count}/{total_count} åªè‚¡ç¥¨ ({success_rate:.1f}%)ï¼Œ"
                  f"è€—æ—¶ {elapsed_total:.1f}ç§’ï¼Œå¹³å‡é€Ÿåº¦ {avg_speed:.1f}åª/ç§’")
            
            # å¦‚æœæœ‰å¤§é‡å¤±è´¥ï¼Œæç¤ºç”¨æˆ·
            if success_rate < 50:
                print(f"âš ï¸ è­¦å‘Š: æˆåŠŸç‡ä»… {success_rate:.1f}%ï¼Œå¯èƒ½æ˜¯æœåŠ¡å™¨é™åˆ¶äº†è¯·æ±‚é¢‘ç‡")
                print(f"ğŸ’¡ å»ºè®®: 1. å¢åŠ ç¼“å­˜æ—¶é—´ 2. å‡å°‘åŒæ­¥é¢‘ç‡ 3. åˆ†å¤šæ¬¡å°æ‰¹é‡åŒæ­¥")
            
            return result
            
        except Exception as e:
            print(f"æ‰¹é‡è·å–å®æ—¶è¡Œæƒ…å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {}
    
    def get_batch_index_data(self, codes: list) -> dict:
        """
        æ‰¹é‡è·å–æŒ‡æ•°æ•°æ®
        
        Args:
            codes: æŒ‡æ•°ä»£ç åˆ—è¡¨ (å¦‚: ['000001', '000300'])
            
        Returns:
            å­—å…¸ï¼Œkeyä¸ºæŒ‡æ•°ä»£ç ï¼Œvalueä¸ºè¡Œæƒ…æ•°æ®
        """
        try:
            result = {}
            
            if not codes:
                return result
            
            # ä»ä»Šå¤©å¼€å§‹å¾€å‰æŸ¥æ‰¾æœ€è¿‘çš„äº¤æ˜“æ—¥
            for i in range(30):
                date = (datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d')
                
                for code in codes:
                    if code in result:
                        continue
                    
                    # æ ‡å‡†åŒ–ä»£ç æ ¼å¼
                    code_with_prefix = code
                    if '.' not in code:
                        if code.startswith('000') or code.startswith('399'):
                            code_with_prefix = f'sz.{code}'
                        elif code.startswith('sh.'):
                            code_with_prefix = code
                        else:
                            code_with_prefix = f'sh.{code}'
                    
                    # å°è¯•ä»ç¼“å­˜è·å–
                    if self.enable_cache and self.cache:
                        cached_data = self.cache.get_spot_data(f"index_{code}", max_age_hours=1)
                        if cached_data is not None:
                            result[code] = cached_data
                            continue
                    
                    try:
                        rs = bs.query_history_k_data_plus(
                            code_with_prefix,
                            "date,code,open,high,low,close,volume,amount,pctChg",
                            start_date=date,
                            end_date=date,
                            frequency="d",
                            adjustflag="3"
                        )
                    except Exception as e:
                        print(f"è·å–æŒ‡æ•° {code} æ•°æ®æ—¶å‡ºé”™: {e}")
                        continue
                    
                    if rs.error_code != '0':
                        continue
                    
                    try:
                        data_list = []
                        while (rs.error_code == '0') & rs.next():
                            data_list.append(rs.get_row_data())
                    except Exception as e:
                        print(f"è§£ææŒ‡æ•° {code} æ•°æ®æ—¶å‡ºé”™: {e}")
                        continue
                    
                    if data_list:
                        df = pd.DataFrame(data_list, columns=rs.fields)
                        index_data = df.iloc[0].to_dict()
                        result[code] = index_data
                        
                        # ä¿å­˜åˆ°ç¼“å­˜
                        if self.enable_cache and self.cache:
                            self.cache.save_spot_data(f"index_{code}", index_data)
                
                # å¦‚æœæ‰€æœ‰æŒ‡æ•°éƒ½è·å–åˆ°äº†æ•°æ®ï¼Œæå‰é€€å‡º
                if len(result) == len(codes):
                    break
            
            return result
            
        except Exception as e:
            print(f"æ‰¹é‡è·å–æŒ‡æ•°æ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {}
    
    def get_historical_data(
        self,
        code: str,
        period: str = "daily",
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        adjust: str = "qfq",
        days: Optional[int] = None,
        max_retries: int = 3
    ) -> pd.DataFrame:
        """
        è·å–è‚¡ç¥¨å†å²Kçº¿æ•°æ®ï¼ˆå¸¦ç¼“å­˜å’Œé‡è¯•æœºåˆ¶ï¼‰
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
            period: å‘¨æœŸ (daily/weekly/monthly)
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DDæ ¼å¼), é»˜è®¤ä¸ºä¸€å¹´å‰
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DDæ ¼å¼), é»˜è®¤ä¸ºä»Šå¤©
            adjust: å¤æƒç±»å‹ (qfq-å‰å¤æƒ, hfq-åå¤æƒ, ä¸å¤æƒ)
            days: è·å–å¤©æ•°ï¼ˆå¦‚æœæŒ‡å®šï¼Œå°†è¦†ç›–start_dateï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            
        Returns:
            DataFrameåŒ…å«OHLCVæ•°æ®
        """
        last_error = None
        
        for attempt in range(max_retries):
            try:
                # å¦‚æœæŒ‡å®šäº†daysï¼Œè®¡ç®—start_date
                if days is not None:
                    start_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
                
                # æ ‡å‡†åŒ–ä»£ç æ ¼å¼
                if '.' not in code:
                    if code.startswith('6'):
                        code = f'sh.{code}'
                    else:
                        code = f'sz.{code}'
                
                # è®¾ç½®é»˜è®¤æ—¥æœŸ
                if end_date is None:
                    end_date = datetime.now().strftime("%Y-%m-%d")
                if start_date is None:
                    start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
                
                # å°è¯•ä»ç¼“å­˜è·å–
                if self.enable_cache and self.cache:
                    cached_data = self.cache.get_historical_data(
                        code, start_date, end_date, max_age_hours=24
                    )
                    if cached_data is not None:
                        print(f"ä»ç¼“å­˜è·å–è‚¡ç¥¨ {code} å†å²æ•°æ®ï¼Œå…± {len(cached_data)} æ¡")
                        return cached_data
                
                # è®¾ç½®å¤æƒæ ‡å¿—
                adjustflag_map = {
                    'qfq': '3',  # å‰å¤æƒ
                    'hfq': '2',  # åå¤æƒ
                    '': '1'      # ä¸å¤æƒ
                }
                adjustflag = adjustflag_map.get(adjust, '3')
                
                # è®¾ç½®é¢‘ç‡
                frequency_map = {
                    'daily': 'd',
                    'weekly': 'w',
                    'monthly': 'm'
                }
                frequency = frequency_map.get(period, 'd')
                
                # è·å–æ•°æ®
                rs = bs.query_history_k_data_plus(
                    code,
                    "date,code,open,high,low,close,volume,amount,pctChg,turn",
                    start_date=start_date,
                    end_date=end_date,
                    frequency=frequency,
                    adjustflag=adjustflag
                )
                
                if rs.error_code != '0':
                    print(f"è·å–è‚¡ç¥¨ {code} å†å²æ•°æ®å¤±è´¥: {rs.error_msg}")
                    return pd.DataFrame()
                
                data_list = []
                while (rs.error_code == '0') & rs.next():
                    data_list.append(rs.get_row_data())
                
                if not data_list:
                    return pd.DataFrame()
                
                result = pd.DataFrame(data_list, columns=rs.fields)
                
                # æ ‡å‡†åŒ–åˆ—å
                result.columns = [
                    'date', 'code', 'open', 'high', 'low', 'close',
                    'volume', 'amount', 'pct_change', 'turnover'
                ]
                
                # è½¬æ¢æ•°æ®ç±»å‹
                result['date'] = pd.to_datetime(result['date'])
                for col in ['open', 'high', 'low', 'close', 'volume', 'amount', 'pct_change', 'turnover']:
                    result[col] = pd.to_numeric(result[col], errors='coerce')
                
                result.set_index('date', inplace=True)
                
                # ä¿å­˜åˆ°ç¼“å­˜
                if self.enable_cache and self.cache:
                    self.cache.save_historical_data(code, result)
                    print(f"å·²ä¿å­˜è‚¡ç¥¨ {code} å†å²æ•°æ®åˆ°ç¼“å­˜ï¼Œå…± {len(result)} æ¡")
                
                return result
                
            except Exception as e:
                last_error = e
                error_str = str(e)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘ç»œé”™è¯¯
                is_network_error = any(keyword in error_str.lower() for keyword in [
                    'utf-8', 'codec', 'decompress', 'invalid', 'connection',
                    '10054', '10053', 'è¿œç¨‹ä¸»æœº', 'ç½‘ç»œ', 'æ¥æ”¶æ•°æ®',
                    'socket', 'timeout', 'reset'
                ])
                
                if is_network_error and attempt < max_retries - 1:
                    wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                    print(f"âš ï¸ ç½‘ç»œé”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {error_str}")
                    print(f"   ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                    continue
                else:
                    print(f"è·å–è‚¡ç¥¨ {code} å†å²æ•°æ®å¤±è´¥: {e}")
                    return pd.DataFrame()
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        print(f"è·å–è‚¡ç¥¨ {code} å†å²æ•°æ®å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡: {last_error}")
        return pd.DataFrame()
    
    def get_index_data(self, index_code: str = "000001") -> pd.DataFrame:
        """
        è·å–æŒ‡æ•°æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰
        
        Args:
            index_code: æŒ‡æ•°ä»£ç  (000001-ä¸Šè¯æŒ‡æ•°, 399001-æ·±è¯æˆæŒ‡, 399006-åˆ›ä¸šæ¿æŒ‡)
            
        Returns:
            DataFrameåŒ…å«æŒ‡æ•°å†å²æ•°æ®
        """
        try:
            # æ ‡å‡†åŒ–ä»£ç æ ¼å¼
            if '.' not in index_code:
                if index_code.startswith('000'):
                    index_code = f'sh.{index_code}'
                else:
                    index_code = f'sz.{index_code}'
            
            end_date = datetime.now().strftime("%Y-%m-%d")
            start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
            
            # å°è¯•ä»ç¼“å­˜è·å–
            if self.enable_cache and self.cache:
                cached_data = self.cache.get_index_data(
                    index_code, start_date, end_date, max_age_hours=1
                )
                if cached_data is not None:
                    print(f"ä»ç¼“å­˜è·å–æŒ‡æ•° {index_code} æ•°æ®ï¼Œå…± {len(cached_data)} æ¡")
                    return cached_data
            
            rs = bs.query_history_k_data_plus(
                index_code,
                "date,code,open,high,low,close,volume,amount,pctChg",
                start_date=start_date,
                end_date=end_date,
                frequency="d",
                adjustflag="3"
            )
            
            if rs.error_code != '0':
                print(f"è·å–æŒ‡æ•° {index_code} æ•°æ®å¤±è´¥: {rs.error_msg}")
                return pd.DataFrame()
            
            data_list = []
            while (rs.error_code == '0') & rs.next():
                data_list.append(rs.get_row_data())
            
            if not data_list:
                return pd.DataFrame()
            
            result = pd.DataFrame(data_list, columns=rs.fields)
            
            # æ ‡å‡†åŒ–åˆ—å
            result.columns = [
                'date', 'code', 'open', 'high', 'low', 'close',
                'volume', 'amount', 'pct_change'
            ]
            
            result['date'] = pd.to_datetime(result['date'])
            for col in ['open', 'high', 'low', 'close', 'volume', 'amount', 'pct_change']:
                result[col] = pd.to_numeric(result[col], errors='coerce')
            
            result.set_index('date', inplace=True)
            
            # ä¿å­˜åˆ°ç¼“å­˜
            if self.enable_cache and self.cache:
                self.cache.save_index_data(index_code, result)
                print(f"å·²ä¿å­˜æŒ‡æ•° {index_code} æ•°æ®åˆ°ç¼“å­˜ï¼Œå…± {len(result)} æ¡")
            
            return result
            
        except Exception as e:
            print(f"è·å–æŒ‡æ•° {index_code} æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_industry_ranking(self, sort_by: str = "change_pct") -> pd.DataFrame:
        """
        è·å–è¡Œä¸šæ¿å—æ¶¨è·Œå¹…æ’è¡Œ
        
        æ³¨æ„: baostockä¸æä¾›è¡Œä¸šæ¿å—æ’è¡Œæ•°æ®ï¼Œæ­¤æ–¹æ³•è¿”å›ç©ºDataFrame
        
        Args:
            sort_by: æ’åºå­—æ®µ
            
        Returns:
            DataFrameåŒ…å«å„è¡Œä¸šæ¿å—æ•°æ®ï¼ˆå½“å‰ä¸ºç©ºï¼‰
        """
        print("æ³¨æ„: baostockä¸æä¾›è¡Œä¸šæ¿å—æ’è¡Œæ•°æ®")
        return pd.DataFrame(columns=['æ¿å—åç§°', 'æ¶¨è·Œå¹…', 'é¢†æ¶¨è‚¡', 'é¢†æ¶¨è‚¡æ¶¨å¹…'])
    
    def clear_cache(self, table: Optional[str] = None):
        """
        æ¸…é™¤ç¼“å­˜
        
        Args:
            table: è¡¨åï¼ˆNoneè¡¨ç¤ºæ¸…é™¤æ‰€æœ‰ï¼‰
        """
        if self.cache:
            self.cache.clear_cache(table)
            print(f"å·²æ¸…é™¤ç¼“å­˜: {table if table else 'æ‰€æœ‰'}")
    
    def get_cache_info(self) -> dict:
        """
        è·å–ç¼“å­˜ä¿¡æ¯
        
        Returns:
            åŒ…å«ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        if self.cache:
            return self.cache.get_cache_info()
        return {}


# ä¾¿æ·å‡½æ•°
def fetch_stock_data(code: str, days: int = 365) -> pd.DataFrame:
    """
    å¿«é€Ÿè·å–è‚¡ç¥¨å†å²æ•°æ®çš„ä¾¿æ·å‡½æ•°
    
    Args:
        code: è‚¡ç¥¨ä»£ç 
        days: è·å–å¤©æ•°
        
    Returns:
        DataFrame
    """
    fetcher = BaoStockDataFetcher()
    start_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
    return fetcher.get_historical_data(code, start_date=start_date)


def fetch_market_data() -> pd.DataFrame:
    """
    è·å–å…¨å¸‚åœºè‚¡ç¥¨æ•°æ®
    
    Returns:
        DataFrameåŒ…å«æ‰€æœ‰Aè‚¡æ•°æ®
    """
    fetcher = BaoStockDataFetcher()
    return fetcher.get_stock_list()
